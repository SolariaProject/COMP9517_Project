{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task3_detectron2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt_SUptnfVmm",
        "outputId": "dec602e7-1bf3-4656-9c67-04e5d1c645a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmxCuclhferE"
      },
      "source": [
        "!cp /gdrive/My\\ Drive/task3_dataset.zip /content\n",
        "!unzip *.zip > /dev/null\n",
        "!rm *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjUSM7mLgOdR",
        "outputId": "5a19a0f4-8223-4ba7-abd9-c00f2d9c84b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "assert torch.__version__.startswith(\"1.7\")\n",
        "!CC=clang CXX=clang++ python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "!pip install split-folders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN1zcNE0Kq-I"
      },
      "source": [
        "!rm -rf task3_dataset/annotation_labeled/\n",
        "!rm -rf output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6kvjmEPKGz-",
        "outputId": "1e0fc2cd-8f6d-4e88-8adf-be68ba76cb3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio('task3_dataset', output=\"leaf\", seed=1337, ratio=(.8, 0.2)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_ftOs3zfpcn"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icd_-uV1I-vi",
        "outputId": "d803849f-581c-44f3-a5ed-ef951c054651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "tags": []
      },
      "source": [
        "# if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
        "# from detectron2.data.datasets import register_coco_instances\n",
        "# register_coco_instances(\"my_dataset_train\", {}, \"json_annotation_train.json\", \"path/to/image/dir\")\n",
        "# register_coco_instances(\"my_dataset_val\", {}, \"json_annotation_val.json\", \"path/to/image/dir\")\n",
        "\n",
        "from detectron2.structures import BoxMode\n",
        "\n",
        "def get_leaf_dicts(img_dir):\n",
        "\n",
        "    dataset_dicts = []\n",
        "    for i in os.listdir(os.path.join(img_dir,'annotation')):\n",
        "        record = {}\n",
        "        \n",
        "        filename = os.path.join(img_dir, 'images',i)\n",
        "        img = cv2.imread(filename)\n",
        "        height, width = img.shape[:2]\n",
        "\n",
        "        colors = np.unique(img)[1:]\n",
        "        \n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = i\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "\n",
        "        contours=[cv2.findContours(np.where(img == c, 255, 0).astype(np.uint8), mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_SIMPLE)[0] for c in colors]\n",
        "        objs=[]\n",
        "        for cnts in contours:\n",
        "            for cnt in cnts:\n",
        "                cnt=cnt.reshape(-1,2)\n",
        "                px = cnt[:,0]\n",
        "                py = cnt[:,1]\n",
        "\n",
        "                poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
        "                \n",
        "                obj = {\n",
        "                    \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "                    \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                    \"segmentation\": [poly],\n",
        "                    \"category_id\": 0,\n",
        "                }\n",
        "                objs.append(obj)\n",
        "            del cnt,px,py\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "        del img,contours,cnts\n",
        "    return dataset_dicts\n",
        "get_leaf_dicts('task3_dataset/')\n",
        "# for d in [\"train\", \"val\"]:\n",
        "#     DatasetCatalog.register(\"leaf_\" + d, lambda d=d: get_leaf_dicts(\"leaf/\" + d + \"/\"))\n",
        "#     MetadataCatalog.get(\"leaf_\" + d).set(thing_classes=[\"leaf\"])\n",
        "# leaf_metadata = MetadataCatalog.get(\"leaf_train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDihRPC0L0mW"
      },
      "source": [
        "## Visualize dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADFeyPw4Lzio",
        "outputId": "6f12bbfa-f932-40c5-9950-927263d39d30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dataset_dicts = get_leaf_dicts(\"leaf/train\")\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=leaf_metadata, scale=1)\n",
        "    out = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imantics import Mask\n",
        "import imageio\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "ara=imageio.imread('task3_dataset/annotation/ara2012_plant001.png')\n",
        "print(ara.shape)\n",
        "plt.imshow(ara)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}